# k维树

标签（空格分隔）： k近邻算法 地图搜索

---
k维树是有序二叉树在N维空间的推广，有序二叉树存储的是一维元素。节点N的左子节点的所有元素总小于N，右子节点的所有元素都大于N，建树和搜索的过程都是递归进行的。

定义： 
* $T_l$ 表示第$l$层子节点， 当前维度dim = l mod n
* $N_i$ 表示N节点第i维值  
* $N^L$ 表示N的左子节点，$N^R$ 表示N的右子节点。 
* Nearest 表示当前搜到的最近点, Min_Distance是搜到的最短距离。
按照同有序二叉树同样的方式，k维树的建立过程轮番在n维空间的各个维度进行。$$T_l:   N_{dim}^L < N_{dim} < N_{dim}^R$$ 在每个维度，都从当前维度里选择中位数点作为N节点，把当前的所有节点一分为二。其实随机选一个点应该也可以，尽量将当前维度均衡划分开。
k维树的搜索过程同二叉树也很类似。$T_l$记录当前节点同目标节点的距离，保留更优的结果（这里如果需要找到k个最近点，可以维护一个有限队列）。然后在左右子节点的当前维度中找离目标节点更近的那一侧（当然是递归的使用k维树搜索算法），搜索进行到下$T_{l+1}$，一直进行到空叶子节点。
当算法开始回退的时候，**如果$abs(Nearest_{dim} - Target_{dim}) < Min_Distance$，那么我们需要搜索离目标节点更远的那一侧节点。如果条件不成立，我们就直接向上回退就好。**这相当于在为搜索过程进行剪枝：如果中间节点都不在Target节点圈定的超球体中， 那么更远侧的所有节点都不可能在其中。

具体的实现代码，可以参见：https://www.zybuluo.com/ErlangZ/note/554637。比较有趣的一点是，k维树可以应用在一种叫KNN的分类算法中，这种分类算法思路很简单，就是规定一种距离的计算方式，在数据样本中找到同目标节点最近的k个节点，这些节点中属于哪种节点更多，目标节点就属于那个类。

##参考文献
《统计学习方法》李航 第三章 KNN分类
 << an Introductory tutorial on kd-trees>> Andrew W. Moore 
