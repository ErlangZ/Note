# 全卷积神经网络
经典的卷积神经网络(比如AlexNet,GoogLeNet等)一般会采用若干个卷积层加上若干个全连接层的结构，这个结构的
问题是输入数据的大小必须固定，越接近输出层的位置，输出的特征图越小, 最终的输出层的每个元素其实只跟
一小块输入层的数据相关。全连接神经网络则在这个基础上，去掉了全连接层,把它们也替换成全连接层，它可以
适应任意大小的输入数据，计算效率很高。

最早提出这个想法的是[^1]一篇用这种网络来做连续字体的手写识别系统的文章。

[^1]:Fully Convolutional Networks for Segmantic Segementation. -- Jonathan Long
